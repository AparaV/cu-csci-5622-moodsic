{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import glob\n",
    "\n",
    "from lib import hdf5_getters\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%aimport lib.hdf5_getters\n",
    "%autoreload 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `music.csv`\n",
    "10,000 songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['artist.hotttnesss', 'artist.id', 'artist.name', 'artist_mbtags',\n",
      "       'artist_mbtags_count', 'bars_confidence', 'bars_start',\n",
      "       'beats_confidence', 'beats_start', 'duration', 'end_of_fade_in',\n",
      "       'familiarity', 'key', 'key_confidence', 'latitude', 'location',\n",
      "       'longitude', 'loudness', 'mode', 'mode_confidence', 'release.id',\n",
      "       'release.name', 'similar', 'song.hotttnesss', 'song.id',\n",
      "       'start_of_fade_out', 'tatums_confidence', 'tatums_start', 'tempo',\n",
      "       'terms', 'terms_freq', 'time_signature', 'time_signature_confidence',\n",
      "       'title', 'year'],\n",
      "      dtype='object')\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "data_path = \"../Data/\"\n",
    "\n",
    "music = pd.read_csv(data_path + \"music.csv\")\n",
    "print(music.columns)\n",
    "print(len(music))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Million Song Dataset\n",
    "Subset of 10,000 songs. Different songs than in `music.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_all_files(basedir, ext='.h5') :\n",
    "    cnt = 0\n",
    "    for root, dirs, files in os.walk(basedir):\n",
    "        files = glob.glob(os.path.join(root,'*'+ext))\n",
    "        cnt += len(files)\n",
    "    return cnt\n",
    "\n",
    "def apply_func_msd(basedir, func, ext='.h5') :\n",
    "    features = []\n",
    "    for root, dirs, files in os.walk(basedir):\n",
    "        files = glob.glob(os.path.join(root,'*'+ext))\n",
    "        for f in files:\n",
    "            h5 = hdf5_getters.open_h5_file_read(f)\n",
    "            features.append( func(h5) )\n",
    "            h5.close()\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    }
   ],
   "source": [
    "msd_data_path = \"D:/Datafiles/MillionSongSubset/data/\"\n",
    "print(count_all_files(msd_data_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bars_confidence <HDF5 dataset \"bars_confidence\": shape (83,), type \"<f8\">\n",
      "bars_start <HDF5 dataset \"bars_start\": shape (83,), type \"<f8\">\n",
      "beats_confidence <HDF5 dataset \"beats_confidence\": shape (344,), type \"<f8\">\n",
      "beats_start <HDF5 dataset \"beats_start\": shape (344,), type \"<f8\">\n",
      "sections_confidence <HDF5 dataset \"sections_confidence\": shape (10,), type \"<f8\">\n",
      "sections_start <HDF5 dataset \"sections_start\": shape (10,), type \"<f8\">\n",
      "segments_confidence <HDF5 dataset \"segments_confidence\": shape (971,), type \"<f8\">\n",
      "segments_loudness_max <HDF5 dataset \"segments_loudness_max\": shape (971,), type \"<f8\">\n",
      "segments_loudness_max_time <HDF5 dataset \"segments_loudness_max_time\": shape (971,), type \"<f8\">\n",
      "segments_loudness_start <HDF5 dataset \"segments_loudness_start\": shape (971,), type \"<f8\">\n",
      "segments_pitches <HDF5 dataset \"segments_pitches\": shape (971, 12), type \"<f8\">\n",
      "segments_start <HDF5 dataset \"segments_start\": shape (971,), type \"<f8\">\n",
      "segments_timbre <HDF5 dataset \"segments_timbre\": shape (971, 12), type \"<f8\">\n",
      "songs <HDF5 dataset \"songs\": shape (1,), type \"|V220\">\n",
      "tatums_confidence <HDF5 dataset \"tatums_confidence\": shape (688,), type \"<f8\">\n",
      "tatums_start <HDF5 dataset \"tatums_start\": shape (688,), type \"<f8\">\n"
     ]
    }
   ],
   "source": [
    "f = h5py.File(msd_data_path + \"A/A/A/TRAAAAW128F429D538.h5\")\n",
    "for key in f['analysis']:\n",
    "    print(key, f['analysis'][key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    }
   ],
   "source": [
    "msd_titles = apply_func_msd(msd_data_path, hdf5_getters.get_title)\n",
    "\n",
    "print(len(msd_titles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
